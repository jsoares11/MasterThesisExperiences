apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      app: kafka
    name: kafka-hs
  spec:
    clusterIP: None
    ports:
    - name: kafkaport
      port: 9093
      protocol: TCP
      targetPort: 9093
    selector:
      app: kafka
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    creationTimestamp: null
    name: kafka-pdb
  spec:
    maxUnavailable: 1
    selector:
      matchLabels:
        app: kafka
  status:
    currentHealthy: 0
    desiredHealthy: 0
    disruptionsAllowed: 0
    expectedPods: 0
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    creationTimestamp: null
    labels:
      app: kafka
    name: kafka
  spec:
    podManagementPolicy: Parallel
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kafka
    serviceName: kafka-hs
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kafka
      spec:
        affinity:
          podAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - zk
                topologyKey: kubernetes.io/hostname
              weight: 1
#          podAntiAffinity:
#            requiredDuringSchedulingIgnoredDuringExecution:
#            - labelSelector:
#                matchExpressions:
#                - key: app
#                  operator: In
#                  values:
#                  - kafka
#              topologyKey: kubernetes.io/hostname
        containers:
        - command:
          - sh
          - -c
          - "(echo 'delete.topic.enable=true' >> kafka_2.12-2.5.0/config/server.properties) & exec kafka_2.12-2.5.0/bin/kafka-server-start.sh kafka_2.12-2.5.0/config/server.properties \
      --override broker.id=${HOSTNAME##*-} \
      --override listeners=PLAINTEXT://:9093 \
      --override zookeeper.connect=zk-cs.kafka.svc.cluster.local:2181 \
      --override advertised.listeners=PLAINTEXT://kafka-${HOSTNAME##*-}.kafka-hs.kafka.svc.cluster.local:9093
      --override log.dir=/var/lib/kafka \
      --override auto.create.topics.enable=true \
      --override auto.leader.rebalance.enable=true \
      --override background.threads=10 \
      --override min.insync.replicas=1 \
      --override num.io.threads=8 \
      --override num.network.threads=3 \
      --override num.recovery.threads.per.data.dir=1 \
      --override num.replica.fetchers=1 \
      --override offset.metadata.max.bytes=4096 \
      --override offsets.commit.required.acks=-1 \
      --override offsets.commit.timeout.ms=5000 \
      --override offsets.load.buffer.size=5242880 \
      --override offsets.retention.check.interval.ms=600000 \
      --override offsets.retention.minutes=1440 \
      --override offsets.topic.compression.codec=0 \
      --override offsets.topic.num.partitions=50 \
      --override offsets.topic.replication.factor=3 \
      --override offsets.topic.segment.bytes=104857600 \
      --override replica.fetch.min.bytes=1 \
      --override replica.fetch.wait.max.ms=500 \
      --override replica.high.watermark.checkpoint.interval.ms=5000 \
      --override replica.lag.time.max.ms=10000 \
      --override replica.socket.receive.buffer.bytes=65536 \
      --override replica.socket.timeout.ms=30000 \
      --override request.timeout.ms=30000 \
      --override socket.receive.buffer.bytes=102400 \
      --override socket.request.max.bytes=104857600 \
      --override socket.send.buffer.bytes=102400 \
      --override unclean.leader.election.enable=true \
      --override zookeeper.session.timeout.ms=6000 \
      --override zookeeper.set.acl=false \
      --override broker.id.generation.enable=true \
      --override default.replication.factor=3 \
      --override log.cleaner.backoff.ms=15000 \
      --override log.cleaner.dedupe.buffer.size=134217728 \
      --override log.cleaner.delete.retention.ms=86400000 \
      --override log.cleaner.enable=true \
      --override log.cleaner.io.buffer.load.factor=0.9 \
      --override log.cleaner.io.buffer.size=524288 \
      --override log.cleaner.io.max.bytes.per.second=1.7976931348623157E308 \
      --override log.cleaner.min.cleanable.ratio=0.5 \
      --override log.cleaner.min.compaction.lag.ms=0 \
      --override log.cleaner.threads=1 \
      --override log.cleanup.policy=delete \
      --override log.index.interval.bytes=4096 \
      --override log.index.size.max.bytes=10485760 \
      --override log.message.timestamp.difference.max.ms=9223372036854775807 \
      --override log.message.timestamp.type=CreateTime \
      --override log.preallocate=false \
      --override log.retention.check.interval.ms=300000 \
      --override max.connections.per.ip=2147483647 \
      --override num.partitions=1 \
      --override replica.fetch.backoff.ms=1000 \
      --override replica.fetch.max.bytes=1048576 \
      --override replica.fetch.response.max.bytes=10485760 \
      --override reserved.broker.max.id=1000 \
      --override delete.topic.enable=true "
          env:
          - name: KAFKA_HEAP_OPTS
            value: -Xmx512M -Xms512M
          - name: KAFKA_OPTS
            value: -Dlogging.level=INFO
          image: josesoares/proxy
          imagePullPolicy: Always
          name: k8skafka
          ports:
          - containerPort: 9093
            name: server
            protocol: TCP
#          readinessProbe:
#            exec:
#              command:
#              - sh
#              - -c
#              - /opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server=localhost:9093
#            failureThreshold: 3
#            periodSeconds: 10
#            successThreshold: 1
#            timeoutSeconds: 1
#          resources:
#            requests:
#              cpu: 500m
#              memory: 1Gi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kafka
            name: datadir
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
#        securityContext:
#          fsGroup: 1000
#          runAsUser: 1000
        terminationGracePeriodSeconds: 30
    updateStrategy:
      type: RollingUpdate
    volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        name: datadir
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
        volumeMode: Filesystem
        storageClassName: standard
  status:
    replicas: 0
kind: List
metadata: {}